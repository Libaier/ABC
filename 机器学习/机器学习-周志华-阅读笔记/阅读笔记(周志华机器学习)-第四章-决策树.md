##4.1 基本流程

递归构建过程。分而治之的思想。

##4.2 划分选择

不断划分，使结点纯度越来越高。

###信息增益

信息熵是一种度量结点纯度的常用方法。

信息增益是指根据某种属性对样本集进行划分的所获得纯度的提升。

###增益率

使用增益率可以减小类别数目较多的属性对模型泛化能力产生的不良影响。

C4.5决策树算法采用了增益率来选择最优划分属性。

但这种方法对数目较少的属性有所偏好。

###基尼指数

CART使用基尼指数来选择划分属性。

##4.3 剪枝处理

剪枝(pruning)是防止过拟合的主要手段。

* 预剪枝

	在确定划分之前先使用验证集验证其精读是否上升，如果得到上升才进行划分。
	
	可减少训练和预测的难度，但基于贪心的方法使其有可能欠拟合。

* 后剪枝                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
	先生成完整的树，然后再根据验证集依次确定是否剪枝。

	一般不会欠拟合，训练时间长。

##4.4 连续与缺失值处理

###连续值处理

C4.5采用二分法（取中位数）对连续值进行处理。二分类

###缺失值处理

*C4.5中，让同一样本以不同概率划分到不同节点中。（感觉有点像增加了样本？？）*

##4.5 多变量决策树

每个节点都是一个线性分类器。