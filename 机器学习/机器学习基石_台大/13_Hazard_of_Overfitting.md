###What is Overfitting?

* 什么是过拟合
	* bad generalization: low Ein, high Eout;
	* overfitting: lower Ein, higher Eout

* 产生过拟合(出车祸)的原因
	* VC维过高(开太快)
	* 有噪声(路不平)
	* 训练数据不足(对路况的了解有限)

###The Role of Noise and Data Size

* 假设数据是由50次幂的曲线产生的，与其通过10次幂的假设曲线去拟合它们，还不如采用简单的2次幂曲线来描绘它的趋势。(有可能会出现)

###Deterministic Noise

* 随机噪音(stochastic noise)
	* 服从高斯分布；

* 确定性噪音 (Deterministic Noise)
	* 还有另一种“噪音”，就是前面提到的由未知的复杂函数f(X) 产生的数据，对于我们的假设也是噪音，这种是确定性噪音。
	* 如果我们的假设空间不包含真正的目标函数f(X)（未知的），那么无论如何H 无法描述f(X) 的全部特征。这时就会发生确定性噪音。它与随机噪音是不同的。
	* 我们可以类比的理解它：在计算机中随机数实际上是“伪随机数”，是通过某个复杂的伪随机数算法产生的，因为它对于一般的程序都是杂乱无章的，我们可以把伪随机数当做随机数来使用。

* overfitting 的因素是：
	* 数据过少；
	* 随机噪音过多；
	* 确定性噪音过多；
	* 假设过于复杂，比目标函数还复杂(excessive power)。

###Dealing with Overfitting

* 从简单的模型开始(开慢点)
* 数据清洗/去噪(搞清楚路况)
* 加大训练集(增加路况讯息)
* 正则(踩刹车)
* 检验(仪表板)
* 个人补充
	* Early stopping是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合。
	* Dropout，正则是通过在代价函数后面加上正则项来防止模型过拟合的。而在神经网络中，有一种方法是通过修改神经网络本身结构来实现的，其名为Dropout。
	* 决策树剪枝